{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import tensorflow.keras.losses as losses\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cara/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2023-05-01 20:13:38.744975: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-05-01 20:13:38.877624: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-05-01 20:13:38.879604: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-01 20:13:40.437311: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shuffling Dataset\n",
      "\n",
      "Splitting Dataset\n",
      "\n",
      "Processing training images\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 624/624 [00:09<00:00, 65.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Processing validation images\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 78/78 [00:01<00:00, 65.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Processing testing images\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 858/858 [00:15<00:00, 56.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training AE model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-01 20:14:12.581765: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:266] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UPAE\n",
      "Decoder\n",
      "Epoch 1/10\n",
      "UPAE Loss\n",
      "UPAE Loss\n",
      "10/10 [==============================] - 32s 3s/step - mse_loss: 3602426.5909 - reconstruction_loss: 2800765.5000 - kl_loss: 369368.5312\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 26s 3s/step - mse_loss: 2216185.5227 - reconstruction_loss: 2036192.0000 - kl_loss: 55400.6445\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 28s 3s/step - mse_loss: 1842129.9318 - reconstruction_loss: 1436906.7500 - kl_loss: 346904.2500\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 28s 3s/step - mse_loss: 1450881.4659 - reconstruction_loss: 1167711.2500 - kl_loss: 284603.5938\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 26s 3s/step - mse_loss: 1203138.3977 - reconstruction_loss: 1017199.1875 - kl_loss: 47435.3047\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 25s 3s/step - mse_loss: 1105949.1591 - reconstruction_loss: 537327.7500 - kl_loss: 592609.8750\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 26s 3s/step - mse_loss: 661664.3153 - reconstruction_loss: 445825.0938 - kl_loss: 30035.2500\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 26s 3s/step - mse_loss: 961700.3466 - reconstruction_loss: -47168.7695 - kl_loss: 419585.6875\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 23s 2s/step - mse_loss: 344440.6090 - reconstruction_loss: 74740.3984 - kl_loss: 385370.4375\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 23s 2s/step - mse_loss: 667021.5852 - reconstruction_loss: 671793.6875 - kl_loss: 184.3173\n"
     ]
    }
   ],
   "source": [
    "%run main3.py --u"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tensorboard will show trends in precision, recall, etc per epochs\n",
    "#tensorboard to be opened in a browser using link \n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir logs/fit"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing using testing set\n",
    "input_images=image_datasets[2] \n",
    "generated = vae.autoencoder.predict(input_images)\n",
    "generated = np.array(generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting mean reconstruction error score for the images tested\n",
    "re_score = losses.mean_squared_error(input_images, generated)\n",
    "re_score = np.mean(re_score)\n",
    "print(\"reconstruction error score:\", re_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input image\n",
    "plt.imshow(image_datasets[2][4])\n",
    "plt.title(\"Input Image\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rescaled generated image\n",
    "generated_rescaled = (generated[0] - generated[0].min()) / (generated[0].max() - generated[0].min())\n",
    "plt.imshow(generated_rescaled.reshape(64,64,3))\n",
    "plt.title(\"Rescaled Generated Image\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reconstruction error without Uncertainty Prediciton Score\n",
    "#for the sample image above\n",
    "re_score = losses.mean_squared_error(image_datasets[2][0], generated_rescaled )\n",
    "re_score = np.mean(re_score)\n",
    "print(\"Vanilla AE Recon Err\", re_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reconstruction error with Uncertainty Prediciton Score\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
